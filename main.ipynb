{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import expon, kurtosis, skew, uniform, lognorm\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "def simulate_log_prices(n, s0, T, m, u, vol, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    time_periods = m * T\n",
    "    delta_t = T / time_periods\n",
    "    zs = np.random.normal(size=(n, time_periods))\n",
    "    exp = (u - vol ** 2 / 2) * delta_t + vol * np.sqrt(delta_t) * zs\n",
    "    prices = np.log(s0) + np.cumsum(exp, axis=1)\n",
    "    return prices\n",
    "\n",
    "\n",
    "def simulate_log_prices_shock(n, s0, T, m, u, vol, shock_func, shock_freq, vol_shock, seed=1):\n",
    "    log_prices = simulate_log_prices(n, s0, T, m, u, vol)\n",
    "    log_prices_shocked = simulate_log_prices(n, s0, T, m, u, vol_shock)\n",
    "    time_periods = m * T\n",
    "    delta_t = T / time_periods\n",
    "\n",
    "    price_diff = log_prices_shocked - log_prices\n",
    "    for i in range(n):\n",
    "        start = int(expon.rvs(scale=shock_freq) / delta_t)\n",
    "        while start < time_periods:\n",
    "            shock = shock_func()\n",
    "            end_index = min(time_periods, start + len(shock))\n",
    "            log_prices[i, start:end_index] += price_diff[i, start:end_index] + shock[:end_index - start]\n",
    "            start += int(expon.rvs(scale=shock_freq) / delta_t)\n",
    "\n",
    "    return log_prices\n",
    "\n",
    "\n",
    "def constant_shock_symmetric(shock_size, shock_length, m):\n",
    "    a = -4 * shock_size / shock_length ** 2\n",
    "    b = shock_size\n",
    "    x = np.linspace(0, shock_length, int(m * shock_length))\n",
    "    shock_values = a * np.square(x - shock_length / 2) + shock_size\n",
    "\n",
    "    def shock():\n",
    "        return shock_values\n",
    "\n",
    "    return shock\n",
    "\n",
    "\n",
    "def plot_prices(prices, title, T, stats, n_paths=100):\n",
    "    prices_plotted = prices[:n_paths]\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    spacing = 0.005\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "    plt.figure(figsize=(12 / 1.1, 5 / 1.1))\n",
    "\n",
    "    ax_price_paths = plt.axes(rect_scatter)\n",
    "    ax_price_paths.tick_params(direction='in', top=True, right=True)\n",
    "    ax_price_paths.set_ylim(prices_plotted.min(),\n",
    "                            prices_plotted.max())\n",
    "    ax_price_paths.set_xlabel('Years', fontsize=13)\n",
    "    ax_price_paths.set_ylabel('Log Price (S0 = 1)', fontsize=13)\n",
    "    ax_price_paths.set_xlim(0, T)\n",
    "    plt.title(title, fontsize=16)\n",
    "\n",
    "    ax_histy = plt.axes(rect_histy)\n",
    "    ax_histy.tick_params(direction='in', labelleft=False)\n",
    "    ax_histy.set_ylim(prices_plotted.min(), prices_plotted.max())\n",
    "    ax_histy.set_xticks([])\n",
    "\n",
    "    ax_price_paths.plot(np.linspace(0, T, prices.shape[1]),\n",
    "                        prices_plotted.T)\n",
    "\n",
    "    terminal_prices = prices[:, -1]\n",
    "    ax_histy.hist(terminal_prices, bins=100, orientation='horizontal', rwidth=1.3, edgecolor='C0')\n",
    "\n",
    "    plt.rc('text', usetex=True)\n",
    "    text = '\\n'.join([\n",
    "        r'\\underline{Terminal Log Prices}', '',\n",
    "        r'$\\mathrm{ann}(\\mu)=%.4f$' % (stats[0] / T),\n",
    "        r'$\\mathrm{ann}(\\sigma)=%.4f$' % (stats[1] / np.sqrt(T)),\n",
    "        r'$\\mathrm{skew}=%.4f$' % stats[2],\n",
    "        r'$\\mathrm{kurtosis}=%.4f$' % stats[3],\n",
    "        r'$\\mathrm{median}=%.4f$' % stats[4],\n",
    "        r'$\\mathrm{max}=%.4f$' % stats[5],\n",
    "        r'$\\mathrm{min}=%.4f$' % stats[6],\n",
    "    ])\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.985, 0.015, text, fontsize=12,\n",
    "             transform=ax_histy.transAxes,\n",
    "             verticalalignment='bottom', bbox=props,\n",
    "             horizontalalignment='right')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def get_stats(terminal_prices):\n",
    "    return (\n",
    "        terminal_prices.mean(),\n",
    "        terminal_prices.std(),\n",
    "        skew(terminal_prices),\n",
    "        kurtosis(terminal_prices),\n",
    "        np.median(terminal_prices),\n",
    "        terminal_prices.max(),\n",
    "        terminal_prices.min()\n",
    "    )\n",
    "\n",
    "\n",
    "def find_jumps(price_path, cutoff):\n",
    "    n = len(price_path)\n",
    "    running_max = [(price_path[0], 0)]\n",
    "    running_min = [(price_path[-1], n - 1)]\n",
    "\n",
    "    for i in range(1, n):\n",
    "        if price_path[i] > running_max[-1][0]:\n",
    "            running_max.append((price_path[i], i))\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        if price_path[i] < running_min[-1][0]:\n",
    "            running_min.append((price_path[i], i))\n",
    "    running_min = running_min[::-1]\n",
    "    running_min_n = len(running_min)\n",
    "\n",
    "    drops = []\n",
    "    min_idx = 0\n",
    "    for price1, max_i in running_max:\n",
    "        price2, min_i = running_min[min_idx]\n",
    "        if max_i == n - 1:\n",
    "            break\n",
    "        while max_i >= min_i:\n",
    "            min_idx += 1\n",
    "            price2, min_i = running_min[min_idx]\n",
    "\n",
    "        drop = price1 - price2\n",
    "        if drop > cutoff:\n",
    "            drops.append((drop, (max_i, min_i)))\n",
    "\n",
    "    drops.sort()\n",
    "\n",
    "    existing_drops = []\n",
    "    while len(drops) > 0:\n",
    "        drop = drops.pop()\n",
    "        start, end = drop[1]\n",
    "        add = True\n",
    "        for _, (existing_start, existing_end) in existing_drops:\n",
    "            if existing_start <= start <= existing_end or existing_start <= end <= existing_end:\n",
    "                add = False\n",
    "                break\n",
    "        if add:\n",
    "            existing_drops.append(drop)\n",
    "    return existing_drops\n",
    "\n",
    "\n",
    "def plot_jumps(price_path, jumps):\n",
    "    index = pd.date_range(start='01/01/1970', end='01/01/2020', periods=len(price_path))\n",
    "    plt.plot(index, price_path, color='black')\n",
    "    for jump, (start, end) in jumps:\n",
    "        plt.plot(index[start:end], price_path[start:end], color='red')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prices = simulate_log_prices(10 ** 4, 1, 252, 100, 0, 0.15432016021070638)\n",
    "jumps = [find_jumps(price_path, -np.log(0.65)) for price_path in prices]\n",
    "long_jumps = [(jump, i) for i, jump in enumerate(jumps) if len(jump) > 2]\n",
    "\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "for jumps_, idx in long_jumps[:4]:\n",
    "    plt.subplot(2, 2, i)\n",
    "    plot_jumps(prices[idx], jumps_)\n",
    "    i += 1\n",
    "fig.suptitle('Log Price with Significant Drops')\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Log Price')\n",
    "plt.show()\n",
    "\n",
    "n_jumps = [len(x) for x in jumps]\n",
    "n_jumps_table = pd.Series(Counter(n_jumps)).rename('Percentage').sort_index()\n",
    "n_jumps_table /= n_jumps_table.sum()\n",
    "n_jumps_table.index.name = 'Number of Drops'\n",
    "print(pd.DataFrame(n_jumps_table).reset_index().to_latex(index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "vol = 0.15\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "\n",
    "shock_length = 1\n",
    "shock = -1\n",
    "shock_parabola = constant_shock_symmetric(shock, shock_length, m)()\n",
    "price_path = simulate_log_prices(1, S0, T, m, u, vol)[0]\n",
    "\n",
    "shocked_path = np.copy(price_path)\n",
    "start_idx = 23\n",
    "shocked_path[start_idx:start_idx + len(shock_parabola)] += shock_parabola\n",
    "\n",
    "x = np.linspace(0, T, m * T)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey='all')\n",
    "axs[0].plot(np.linspace(0, shock_length, m), shock_parabola)\n",
    "axs[0].set_title('Shock Parabola')\n",
    "axs[1].plot(x, price_path)\n",
    "axs[1].set_title('Log Price Path')\n",
    "axs[2].plot(x, shocked_path)\n",
    "axs[2].set_title('Price Path with Shock Parabola')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shocks = np.array([0.3, 0.5, 0.7])\n",
    "log_shocks = -np.log(1 - shocks)\n",
    "percents = [f'{shock * 100}%' for shock in shocks]\n",
    "print(pd.DataFrame({'Price Shock': shocks, 'Price Drop (%)': percents, 'Log Price Shock': log_shocks}).to_latex(\n",
    "    index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "vol = 0.15\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "\n",
    "vanilla_prices = simulate_log_prices(n, S0, T, m, u, vol)\n",
    "terminal_prices = vanilla_prices[:, -1]\n",
    "stats = get_stats(terminal_prices)\n",
    "plot_prices(vanilla_prices, 'Vanilla Log Prices', T, stats, bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "vol = 0.15\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "\n",
    "shocks = np.log(1 - np.array([0.3, 0.5, 0.7]))\n",
    "shock_freq = 3\n",
    "shock_length = 1\n",
    "\n",
    "for shock in shocks:\n",
    "    shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    shock_ = np.round(1 - np.exp(shock), 2)\n",
    "    plot_prices(prices, f'Log Prices (shock={shock_}, length={shock_length}, frequency={shock_freq})', T, stats, bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('volatility_SP500_index_110_day_S0237_series.csv', index_col='Date', parse_dates=True)[['S&P 500']]\n",
    "\n",
    "\n",
    "def fix_date(x):\n",
    "    year = x.year\n",
    "    if x.year > 2022:\n",
    "        year = x.year - 100\n",
    "    return datetime.date(year, x.month, x.day)\n",
    "\n",
    "\n",
    "sp500.index = pd.to_datetime(pd.Series(sp500.index).apply(fix_date))\n",
    "sp500.sort_index(inplace=True)\n",
    "sp500['log_returns'] = np.log(sp500['S&P 500']) - np.log(sp500['S&P 500'].shift(1))\n",
    "sp500['log_return_annual'] = 252 * sp500['log_returns']\n",
    "sp500['log_vol'] = sp500['log_returns'].rolling('100D').std(ddof=0) * np.sqrt(252)\n",
    "\n",
    "sp500 = sp500.dropna()\n",
    "\n",
    "cutoff_quantile = 0.6\n",
    "\n",
    "cutoff = sp500['log_vol'].quantile(cutoff_quantile)\n",
    "non_shock_mean = sp500['log_vol'][sp500['log_vol'] < cutoff].mean()\n",
    "shock_mean = sp500['log_vol'].mean()\n",
    "plt.rc('text', usetex=False)\n",
    "plt.figure(figsize=(6.4, 2.4))\n",
    "plt.plot(sp500['S&P 500'])\n",
    "plt.title('S&P 500 Price')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shocks = np.log(1 - np.linspace(1, 99, 50) / 100)\n",
    "shock_freqs = np.linspace(1, 10, 41)\n",
    "shock_lengths = np.linspace(0.5, 2, 40)\n",
    "Ts = np.linspace(1, 20, 40).astype(int)\n",
    "n = 10 ** 5\n",
    "\n",
    "T = constant_T = 5\n",
    "shock = constant_shock = np.log(0.65)\n",
    "shock_freq = constant_freq = 2\n",
    "shock_length = constant_length = 1\n",
    "\n",
    "res = []\n",
    "\n",
    "vol_shock = 0.181\n",
    "vol = shock_mean\n",
    "\n",
    "for T in Ts:\n",
    "    shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol_shock)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{shock_freq},{shock_length},{shock},{str(stats)[1:-1]}')\n",
    "f = open(\"simulation_data_T.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()\n",
    "res = []\n",
    "T = constant_T\n",
    "\n",
    "for shock_freq in shock_freqs:\n",
    "    shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol_shock)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{shock_freq},{shock_length},{shock},{str(stats)[1:-1]}')\n",
    "f = open(\"simulation_data_shock_freq.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()\n",
    "res = []\n",
    "shock_freq = constant_freq\n",
    "\n",
    "for shock_length in shock_lengths:\n",
    "    shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol_shock)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{shock_freq},{shock_length},{shock},{str(stats)[1:-1]}')\n",
    "f = open(\"simulation_data_shock_length.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()\n",
    "res = []\n",
    "shock_length = constant_length\n",
    "\n",
    "for shock in shocks:\n",
    "    shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol_shock)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{shock_freq},{shock_length},{shock},{str(stats)[1:-1]}')\n",
    "\n",
    "f = open(\"simulation_data_shock.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = ['T', 'shock_freq', 'shock_length', 'shock', 'mean', 'sd', 'skew', 'kurtosis', 'median', 'max', 'min']\n",
    "\n",
    "fields = ['mean', 'sd']\n",
    "data_T = pd.read_csv('simulation_data_T.csv', names=header).set_index('T')[fields]\n",
    "data_shock_freq = pd.read_csv('simulation_data_shock_freq.csv', names=header).set_index('shock_freq')[fields]\n",
    "data_shock_length = pd.read_csv('simulation_data_shock_length.csv', names=header).set_index('shock_length')[fields]\n",
    "data_shock = pd.read_csv('simulation_data_shock.csv', names=header).set_index('shock')[fields]\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "axs[0, 0].plot(data_T.index, data_T, label=fields)\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_title('Time to Maturity')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].plot(1 - np.exp(data_shock.index), data_shock, label=fields)\n",
    "axs[0, 1].set_xlabel('Drop in Price')\n",
    "axs[0, 1].set_title('Shock')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 0].plot(data_shock_freq.index, data_shock_freq, label=fields)\n",
    "axs[1, 0].set_xlabel('Frequency')\n",
    "axs[1, 0].set_title('Shock Frequency')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].plot(data_shock_length.index, data_shock_length, label=fields)\n",
    "axs[1, 1].set_xlabel('Length')\n",
    "axs[1, 1].set_title('Shock Length')\n",
    "axs[1, 1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fields = ['skew', 'kurtosis']\n",
    "data_T = pd.read_csv('simulation_data_T.csv', names=header).set_index('T')[fields]\n",
    "data_shock_freq = pd.read_csv('simulation_data_shock_freq.csv', names=header).set_index('shock_freq')[fields]\n",
    "data_shock_length = pd.read_csv('simulation_data_shock_length.csv', names=header).set_index('shock_length')[fields]\n",
    "data_shock = pd.read_csv('simulation_data_shock.csv', names=header).set_index('shock')[fields]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "axs[0, 0].plot(data_T.index, data_T, label=fields)\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_title('Time to Maturity')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].plot(1 - np.exp(data_shock.index), data_shock, label=fields)\n",
    "axs[0, 1].set_xlabel('Drop in Price')\n",
    "axs[0, 1].set_title('Shock')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 0].plot(data_shock_freq.index, data_shock_freq, label=fields)\n",
    "axs[1, 0].set_xlabel('Frequency')\n",
    "axs[1, 0].set_title('Shock Frequency')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].plot(data_shock_length.index, data_shock_length, label=fields)\n",
    "axs[1, 1].set_xlabel('Length')\n",
    "axs[1, 1].set_title('Shock Length')\n",
    "axs[1, 1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sp500['100 Day Rolling Log Return Volatility'] = sp500['log_vol']\n",
    "sp500['100 Day Rolling Log Return Volatility'].plot()\n",
    "plt.title('100 Day Rolling Log Return Volatility')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sp500['100 Day Rolling Log Return Volatility'].describe().to_latex())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cutoff_quantile = 0.6\n",
    "\n",
    "cutoff = sp500['log_vol'].quantile(cutoff_quantile)\n",
    "vol_non_shock_mean = sp500['log_vol'][sp500['log_vol'] < cutoff].mean()\n",
    "\n",
    "print(\n",
    "    f'We can see from above that the annualized volatility hovers around 15\\% (including shocks). We can compute the volatility without shocks by computing the mean volatility using the bottom {cutoff_quantile * 100}\\\\% of values. We find this number to be {np.round(vol_non_shock_mean, 5) * 100}\\\\%\\\\\\\\')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "past_events = pd.read_csv(\"SP 500 events for response curve 6.csv\", parse_dates=True)\n",
    "\n",
    "past_events = past_events.rename(lambda col: col.replace('Catalyst: ', ''), axis=1)\n",
    "past_events['End Date'] = pd.to_datetime(past_events['End Date'])\n",
    "past_events['Start Date'] = pd.to_datetime(past_events['Start Date'])\n",
    "past_events['Minimum Date'] = pd.to_datetime(past_events['Minimum Date'])\n",
    "past_events['Shock Length'] = past_events['End Date'] - past_events['Start Date']\n",
    "\n",
    "past_events = past_events.sort_values(\"Start Date\")\n",
    "\n",
    "past_events['Time_Between_Shocks'] = past_events['Start Date'].diff()\n",
    "\n",
    "\n",
    "def get_return(df):\n",
    "    i = sp500.index.searchsorted(df['Start Date'])\n",
    "    beg_price = sp500['S&P 500'].iloc[i]\n",
    "\n",
    "    i = sp500.index.searchsorted(df['Minimum Date'])\n",
    "    bot_price = sp500['S&P 500'].iloc[i]\n",
    "\n",
    "    annualization_factor = np.sqrt(252 / np.busday_count(df['Start Date'].date(), df['Minimum Date'].date()))\n",
    "    return np.exp(annualization_factor * np.log(bot_price / beg_price)) - 1\n",
    "\n",
    "\n",
    "# past_events = past_events.loc[past_events.index[np.log(past_events.Shock+1) <- shock_mean]]\n",
    "past_events['time_between_shocks'] = past_events['Time_Between_Shocks'].dt.days\n",
    "past_events['shock_length'] = past_events['Shock Length'].dt.days\n",
    "past_events['Shock Length '] = past_events['shock_length']\n",
    "\n",
    "past_events['Shock'] = past_events.apply(get_return, axis=1)\n",
    "\n",
    "past_events['Shock Frequency'] = past_events['Time_Between_Shocks']\n",
    "past_events['Shock Frequency '] = past_events['time_between_shocks']\n",
    "\n",
    "past_events[['Shock', 'Shock Length ', 'Shock Frequency ']].hist(bins=15)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(r'\\begin{center}')\n",
    "print(past_events[['Shock', 'Shock Length', 'Shock Frequency']].describe().to_latex())\n",
    "print(r'\\end{center}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "\n",
    "\n",
    "def random_shock_symmetric(m):\n",
    "    shock_params = lognorm.fit(-np.log(past_events['Shock'] + 1))\n",
    "    shock_length_params = lognorm.fit(past_events['shock_length'] / 365)\n",
    "    shock_size_rv = lognorm(shock_params[0], 0, shock_params[2])\n",
    "    shock_length_rv = lognorm(shock_length_params[0], 0, shock_length_params[2])\n",
    "\n",
    "    def shock():\n",
    "        shock_size = -shock_size_rv.rvs()\n",
    "        shock_length = shock_length_rv.rvs()\n",
    "        return constant_shock_symmetric(shock_size, shock_length, m)()\n",
    "\n",
    "    return shock\n",
    "\n",
    "\n",
    "shock_freq = past_events['time_between_shocks'].mean() / 365\n",
    "#\n",
    "shock_func = random_shock_symmetric(m)\n",
    "prices = simulate_log_prices_shock(n, S0, T, m, u, non_shock_mean, shock_func, shock_freq, 0.125)\n",
    "terminal_prices = prices[:, -1]\n",
    "stats = get_stats(terminal_prices)\n",
    "plot_prices(prices, f'Log Stock Prices (frequency={np.round(shock_freq, 3)} years)', T, stats, bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ts = np.arange(1, 31)\n",
    "res = []\n",
    "for T in Ts:\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, non_shock_mean, shock_func, shock_freq, 0.125)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{shock_freq},{shock_length},{shock},{str(stats)[1:-1]}')\n",
    "f = open(\"simulation_data_T_real.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = ['T', 'shock_freq', 'shock_length', 'shock', 'mean', 'sd', 'skew', 'kurtosis', 'median', 'max', 'min']\n",
    "fields = ['mean', 'sd']\n",
    "data_T = pd.read_csv('simulation_data_T_real.csv', names=header).set_index('T')[fields]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].plot(data_T.index, data_T, label=fields)\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_title('Time to Maturity vs Mean/Volatility')\n",
    "axs[0].legend()\n",
    "\n",
    "fields = ['skew', 'kurtosis']\n",
    "data_T = pd.read_csv('simulation_data_T_real.csv', names=header).set_index('T')[fields]\n",
    "axs[1].plot(data_T.index, data_T, label=fields)\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_title('Time to Maturity vs Skew/Kurtosis')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_T = pd.read_csv('simulation_data_T_real.csv', names=header)\n",
    "data_T['Log_T'] = np.log(data_T['T'])\n",
    "\n",
    "skew_fit = sm.OLS.from_formula('skew ~ Log_T', data_T).fit()\n",
    "kurt_fit = sm.OLS.from_formula('kurtosis ~ Log_T', data_T).fit()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].plot(data_T.index, data_T['kurtosis'], label='Simulated Kurtosis')\n",
    "axs[0].plot(data_T.index, kurt_fit.predict(), label='OLS Fit Kurtosis')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_title('Kurtosis')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(data_T.index, data_T['skew'], label='Simulated Skew')\n",
    "axs[1].plot(data_T.index, skew_fit.predict(), label='OLS Fit Skew')\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_title('Skew')\n",
    "axs[1].legend()\n",
    "plt.show()\n",
    "print('\\\\\\\\\\\\\\\\')\n",
    "print(kurt_fit.summary().as_latex())\n",
    "print('\\\\pagebreak')\n",
    "print(skew_fit.summary().as_latex())\n",
    "print('\\\\\\\\\\\\\\\\')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shock_type_freq = pd.DataFrame.from_dict({\n",
    "    'Shock Type': [list(past_events)[i] for i in range(4, 8)],\n",
    "    'Frequency': [(past_events.iloc[:, i] == 1).sum() / len(past_events) for i in range(4, 8)]\n",
    "})\n",
    "print(shock_type_freq.to_latex(index=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.suptitle(\"Shock Parameters By Shock Type\", fontsize='x-large')\n",
    "\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 4] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[0, :2])\n",
    "plt.figtext(0.28, 0.87, list(past_events)[4], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 5] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[0, 2:])\n",
    "plt.figtext(0.75, 0.87, list(past_events)[5], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 6] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[1, :2])\n",
    "plt.figtext(0.28, 0.43, list(past_events)[6], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 7] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[1, 2:])\n",
    "plt.figtext(0.75, 0.43, list(past_events)[7], va=\"center\", ha=\"center\", )\n",
    "fig.tight_layout(h_pad=4)\n",
    "fig.subplots_adjust(top=0.78)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4)\n",
    "fig.suptitle(\"Shock Parameters By Shock Type\", fontsize='x-large')\n",
    "\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 4] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[0, :2])\n",
    "plt.figtext(0.28, 0.87, list(past_events)[4], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 5] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[0, 2:])\n",
    "plt.figtext(0.75, 0.87, list(past_events)[5], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 6] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[1, :2])\n",
    "plt.figtext(0.28, 0.43, list(past_events)[6], va=\"center\", ha=\"center\", )\n",
    "past_events.loc[past_events.index[(past_events.iloc[:, 7] == 1)]][['Shock', 'Shock Length ']].hist(ax=axs[1, 2:])\n",
    "plt.figtext(0.75, 0.43, list(past_events)[7], va=\"center\", ha=\"center\", )\n",
    "fig.tight_layout(h_pad=4)\n",
    "fig.subplots_adjust(top=0.78)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "get_event_rows = lambda i: past_events.loc[past_events.index[(past_events.iloc[:, i] == 1)]]\n",
    "\n",
    "shock_types = [\n",
    "    {\n",
    "        'shock_size_rv': uniform(*(uniform.fit(get_event_rows(4)['Shock']))),\n",
    "        'shock_length_rv': uniform(*(uniform.fit(get_event_rows(4)['shock_length'] / 365)))\n",
    "    },\n",
    "    {\n",
    "        'shock_size_rv': lognorm(*(lognorm.fit(-get_event_rows(5)['Shock']))),\n",
    "        'shock_length_rv': lognorm(*(lognorm.fit(get_event_rows(5)['shock_length'] / 365)))\n",
    "    },\n",
    "    {\n",
    "        'shock_size_rv': lognorm(*(lognorm.fit(-get_event_rows(6)['Shock']))),\n",
    "        'shock_length_rv': uniform(*(uniform.fit(get_event_rows(6)['shock_length'] / 365)))\n",
    "    },\n",
    "    {\n",
    "        'shock_size_rv': lognorm(*(lognorm.fit(-get_event_rows(7)['Shock']))),\n",
    "        'shock_length_rv': lognorm(*(np.where([0, 1, 0], 0, lognorm.fit(get_event_rows(7)['shock_length'] / 365))))\n",
    "    },\n",
    "]\n",
    "\n",
    "shock_probs = shock_type_freq['Frequency']\n",
    "\n",
    "\n",
    "def generate_numbers(n, rng):\n",
    "    choices = rng.choice(4, p=shock_probs, size=n)\n",
    "\n",
    "\n",
    "def weighted_random(w, n):\n",
    "    cumsum = np.cumsum(w)\n",
    "    rdm_unif = np.random.rand(n)\n",
    "    return np.searchsorted(cumsum, rdm_unif)\n",
    "\n",
    "\n",
    "def real_shock_symmetric(m):\n",
    "    numbers = [{'shock_size_rv': [], 'shock_length_rv': []} for _ in range(4)]\n",
    "    choices = []\n",
    "\n",
    "    def shock():\n",
    "        nonlocal choices\n",
    "        if len(choices) == 0:\n",
    "            choices = random.choices(range(4), weights=shock_probs, k=1000)\n",
    "        shock_rvs_idx = choices.pop()\n",
    "        if len(numbers[shock_rvs_idx]['shock_size_rv']) == 0:\n",
    "            numbers[shock_rvs_idx]['shock_size_rv'] = shock_types[shock_rvs_idx]['shock_size_rv'].rvs(\n",
    "                size=1000).tolist()\n",
    "            numbers[shock_rvs_idx]['shock_length_rv'] = shock_types[shock_rvs_idx]['shock_length_rv'].rvs(\n",
    "                size=1000).tolist()\n",
    "\n",
    "        shock_length = numbers[shock_rvs_idx]['shock_length_rv'].pop()\n",
    "        shock_size = numbers[shock_rvs_idx]['shock_size_rv'].pop()\n",
    "        return constant_shock_symmetric(-shock_size, shock_length, m)()\n",
    "\n",
    "    return shock\n",
    "\n",
    "\n",
    "shock_freq = past_events['time_between_shocks'].mean() / 365\n",
    "shock_func = real_shock_symmetric(m)\n",
    "prices = simulate_log_prices_shock(n, S0, T, m, u, non_shock_mean, shock_func, shock_freq, shock_mean * 1.07)\n",
    "terminal_prices = prices[:, -1]\n",
    "stats = get_stats(terminal_prices)\n",
    "plot_prices(prices, f'Log Stock Prices (frequency={np.round(shock_freq, 3)} years)', T, stats, bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ts = np.arange(1, 31)\n",
    "res = []\n",
    "for T in Ts:\n",
    "    prices = simulate_log_prices_shock(n, S0, T, m, u, non_shock_mean, shock_func, shock_freq, shock_mean * 1.07)\n",
    "    terminal_prices = prices[:, -1]\n",
    "    stats = get_stats(terminal_prices)\n",
    "    res.append(f'{T},{str(stats)[1:-1]}')\n",
    "f = open(\"simulation_data_T_real2.csv\", \"w\")\n",
    "f.write('\\n'.join(res))\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = ['T', 'mean', 'sd', 'skew', 'kurtosis', 'median', 'max', 'min']\n",
    "fields = ['mean', 'sd']\n",
    "data_T = pd.read_csv('simulation_data_T_real2.csv', names=header).set_index('T')[fields]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].plot(data_T.index, data_T, label=fields)\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_title('Time to Maturity vs Mean/Volatility')\n",
    "axs[0].legend()\n",
    "\n",
    "fields = ['skew', 'kurtosis']\n",
    "data_T = pd.read_csv('simulation_data_T_real2.csv', names=header).set_index('T')[fields]\n",
    "axs[1].plot(data_T.index, data_T, label=fields)\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_title('Time to Maturity vs Skew/Kurtosis')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "header = ['T', 'mean', 'sd', 'skew', 'kurtosis', 'median', 'max', 'min']\n",
    "data_T = pd.read_csv('simulation_data_T_real2.csv', names=header)\n",
    "data_T['Log_T'] = np.log(data_T['T'])\n",
    "\n",
    "skew_fit = sm.OLS.from_formula('skew ~ Log_T', data_T).fit()\n",
    "kurt_fit = sm.OLS.from_formula('kurtosis ~ Log_T', data_T).fit()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].plot(data_T.index, data_T['kurtosis'], label='Simulated Kurtosis')\n",
    "axs[0].plot(data_T.index, kurt_fit.predict(), label='OLS Fit Kurtosis')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_title('Kurtosis')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(data_T.index, data_T['skew'], label='Simulated Skew')\n",
    "axs[1].plot(data_T.index, skew_fit.predict(), label='OLS Fit Skew')\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_title('Skew')\n",
    "axs[1].legend()\n",
    "plt.show()\n",
    "\n",
    "print('\\\\\\\\\\\\\\\\')\n",
    "print(kurt_fit.summary().as_latex())\n",
    "# print('\\\\pagebreak')\n",
    "print(skew_fit.summary().as_latex())\n",
    "print('\\\\\\\\\\\\\\\\')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10 ** 5\n",
    "\n",
    "vol = 0.15\n",
    "T = 5\n",
    "m = 12\n",
    "u = r = 0.07\n",
    "S0 = 1\n",
    "bins = 200\n",
    "\n",
    "Ts = [5, 30]\n",
    "shock_freqs = [3, 7]\n",
    "shock_lengths = [1, 2]\n",
    "shocks = np.log(1 - np.array([0.3, 0.5, 0.7]))\n",
    "for T in Ts:\n",
    "    vanilla_prices = simulate_log_prices(n, S0, T, m, u, vol)\n",
    "    exp_vanilla_prices = np.exp(vanilla_prices)\n",
    "    for shock_freq in shock_freqs:\n",
    "        for shock_length in shock_lengths:\n",
    "            for shock in shocks:\n",
    "                shock_func = constant_shock_symmetric(shock, shock_length, m)\n",
    "                prices = simulate_log_prices_shock(n, S0, T, m, u, vol, shock_func, shock_freq, vol)\n",
    "                terminal_prices = prices[:, -1]\n",
    "                stats = get_stats(terminal_prices)\n",
    "                shock_ = np.round(1 - np.exp(shock), 2)\n",
    "                plot_prices(prices, f'Log Prices (shock={shock_}, length={shock_length}, frequency={shock_freq})', T,\n",
    "                            stats, bins)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_old_return(days_back):\n",
    "    def from_date(date):\n",
    "        i = sp500.index.searchsorted(date - datetime.timedelta(days_back))\n",
    "        j = sp500.index.searchsorted(date)\n",
    "        return sp500['S&P 500'][j] / sp500['S&P 500'][i]\n",
    "\n",
    "    return from_date\n",
    "\n",
    "\n",
    "def get_old_vol(days_back):\n",
    "    def from_date(date):\n",
    "        i = sp500.index.searchsorted(date - datetime.timedelta(days_back))\n",
    "        j = sp500.index.searchsorted(date)\n",
    "        return sp500['log_returns'][i:j].std(ddof=0) * np.sqrt(252)\n",
    "\n",
    "    return from_date\n",
    "\n",
    "\n",
    "def get_old_skew(days_back):\n",
    "    def from_date(date):\n",
    "        i = sp500.index.searchsorted(date - datetime.timedelta(days_back))\n",
    "        j = sp500.index.searchsorted(date)\n",
    "        return skew(sp500['log_returns'][i:j])\n",
    "\n",
    "    return from_date\n",
    "\n",
    "\n",
    "formula = []\n",
    "days_list = [30, 90, 180, 360, 540, 720]\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "for days in days_list:\n",
    "    past_events[f'log_return_{days}'] = past_events['Start Date'].apply(get_old_return(days))\n",
    "    past_events[f'log_vol_{days}'] = past_events['Start Date'].apply(get_old_vol(days))\n",
    "    past_events[f'log_skew_{days}'] = past_events['Start Date'].apply(get_old_skew(days))\n",
    "    formula.append(f'log_return_{days}')\n",
    "    formula.append(f'log_vol_{days}')\n",
    "    formula.append(f'log_skew_{days}')\n",
    "\n",
    "\n",
    "def plot_run_up(days_list, shock_param):\n",
    "    fig, axs = plt.subplots(len(days_list), 3, figsize=(10, len(days_list) * 2))\n",
    "    stats = ['return', 'vol', 'skew']\n",
    "    for i, days in enumerate(days_list):\n",
    "        for j, stat in enumerate(stats):\n",
    "            axs[i, j].scatter(past_events[f'log_{stat}_{days}'], past_events[shock_param])\n",
    "            axs[i, j].set_title(f'log {stat} {days} vs \\n{shock_param}', fontsize=14)\n",
    "            axs[i, j].set_xlabel(f'log {stat} {days}')\n",
    "            axs[i, j].set_ylabel(shock_param.replace('_', ' '))\n",
    "            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "            x = np.ma.masked_invalid(past_events[f'log_{stat}_{days}'])\n",
    "            y = np.ma.masked_invalid(past_events[shock_param])\n",
    "            msk = (~x.mask & ~y.mask)\n",
    "            corr = np.ma.corrcoef(x[msk], y[msk])[1, 0]\n",
    "\n",
    "            t = f\"Corr: {np.round(corr, 3)}\"\n",
    "            axs[i, j].text(0.99, 0.01, t, fontsize=12,\n",
    "                           transform=axs[i, j].transAxes,\n",
    "                           verticalalignment='bottom', bbox=props,\n",
    "                           horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)\n",
    "    print(f'\\\\subsubsection{{Run Up vs {shock_param.replace(\"_\", \" \")}}}')\n",
    "    f = f'{shock_param} ~ {\"+\".join(formula)}'\n",
    "    print(\n",
    "        sm.OLS.from_formula(f, past_events).fit().get_robustcov_results(cov_type='HAC', maxlags=1).summary().as_latex())\n",
    "\n",
    "\n",
    "plot_run_up(days_list, 'Shock')\n",
    "plot_run_up(days_list, 'shock_length')\n",
    "plot_run_up(days_list, 'time_between_shocks')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}